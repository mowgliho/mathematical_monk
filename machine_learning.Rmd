---
title: "Information Theory"
output:
  html_document:
    toc: true
    toc_depth: 2
---

# 1.1: Machine learning: overview and applications

- Machine learning is defined here as algorithms for inferring unknowns from knowns
  - subfield of statistics focusing on algorithms
- Many different applications

# 1.2: What is supervised learning?

- Supervised learning: Given $(x^1,y^1),\dots,(x^n,y^n)$, where $x^i$ are data points, $y^i$ are class/value, we want to choose a function $f(x) = y$
  - and be able to generalize to new $x$ points.
  - Classification: $y^i\in \mathcal{Y}$, where $\mathcal{Y}$ is a finite set
  - Regression $y^i \in \mathbb{R}^d$
    - note that the word "regression" is historical

# 1.3: What is unsupervised learning

- Unsupervised learning is well defined
  - Given $(x^1,\dots,x^n)$, typically $x^i\in \mathbb{R}^k$, find "patterns" in the data
    - Clustering: separate data into clusters
    - Density estimation: find a function for the density of the data
    - Dimensionality reduction: find a lower dimensional space to represent data

# 1.4: Variations on supervised and unsupervised

- Semi-supervised Learning: get labeled data $(x^1,y^1),\dots,(x^k,y^k)$, unlabeled $x^{k+1},\dots,x^n$
  - the task is to predict the labels $y^{k+1},\dots,y^n$
  - i.e. we know the location of the unlabeled points
- Active Learning: get labeled data $(x^1,y^1),\dots,(x^k,y^k)$, unlabeled $x^{k+1},\dots,x^n$
  - can ask for $y^k$'s for particular points $x^k$
  - and after ask for a few points, make predictions on the rest
- Decision theory: How to decide to measure errors/loss functions
  - e.g. weight false positives more than false negatives (e.g. a doctor deciding to do a test)
- Reinforcement Learning: Make actions to maximize long term rewards and minimize overall losses, improve model as go along.

# 1.5: Generative vs discriminative models

- Discrimative: Model $\mathbb{P}(y|x)$, i.e. the class of a given point $x$
- Generative: Model the joint distribution $\mathbb{P}(x,y)$
- can use generative to discriminate by comparing probabilities
- creating generative models takes a lot of data, have to estimate things, etc, so often discriminative models are better - and more appropriate to the problem at hand.
